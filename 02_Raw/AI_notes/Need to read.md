# Non AI model related
- [ ] [**How to make good notes: Evergreen notes**](https://notes.andymatuschak.org/Evergreen_notes)
- [ ] [**Good Book: Shape up**](https://basecamp.com/shapeup)
- [ ] [**Growing and running your data science team**](https://eugeneyan.com/writing/data-science-teams/)
- [ ] [**Way of thinking: Work with garage door up**](https://notes.andymatuschak.org/About_these_notes?stackedNotes=z21cgR9K3UcQ5a7yPsj2RUim3oM2TzdBByZu)
- [ ] [**CS329s Machine Learning Systems Design**](https://docs.google.com/document/d/1b9iuZiDEGVLHyMmnf6w2y1aN6yWQhAyqk3GHlpI9q6M/edit?usp=drivesdk)
- [ ] [**Book: what engineers know and how they know it**]
- [ ] [**TextBook: Patterns, predictions, and actions: A story about machine learning**](https://arxiv.org/abs/2102.05242)
- [ ] [Career time preference](https://commoncog.com/blog/your-time-preference)
- [ ] [Feature level of an app](https://eugeneyan.com/writing/feature-stores/)
- [ ] [Feature stores - A hierarchy of needs](https://eugeneyan.com/writing/feature-stores/)
- [ ] [# A hitchhiker guide to momentum](https://twitter.com/fpedregosa/status/1366747636246659085?s=08)
- [ ] [Book: Subliminal how your unconsious mind rules your behavior]()
- [ ] [Writing at Work - The Why, What, How Framework](https://eugeneyan.com/writing/writing-docs-why-what-how/)
- [ ] [**Writing at Work - Design Docs for Machine Learning Systems**](https://eugeneyan.com/writing/ml-design-docs/)
- [ ] [# Deep Learning In Production Course](https://github.com/The-AI-Summer/Deep-Learning-In-Production)
- [ ] [Testing for AI project in production](https://twitter.com/GokuMohandas/status/1369261247993176066?s=1001)
- [ ] [Recent Explainable AI](https://theaisummer.com/xai/)
- [ ] [When to use quantitative and when to use qualitative color scales](https://blog.datawrapper.de/quantitative-vs-qualitative-color-scales/)
- [ ] [Seven habit that shape my last decade](https://twitter.com/eugeneyan/status/1371987166524366848?s=1001)
- [ ] [Awesome Leadership and Management](https://github.com/LappleApple/awesome-leading-and-managing)
- [ ] [# Fireside Chat with Data Science and Engineering](https://eugeneyan.com/speaking/bukalapak-fireside/)
- [ ] [** Planning Your Career: Values and Superpowers**](https://eugeneyan.com/writing/values-and-superpowers/)
- [ ] [Deep learning design pattern book](https://livebook.manning.com/book/deep-learning-design-patterns/chapter-6/v-5/12)
- [ ] [Best resource to learn deep learning theory](https://theaisummer.com/deep-learning-theory-resources/)
- [ ] [# The Cook and the Chef: Musk’s Secret Sauce](https://waitbutwhy.com/2015/11/the-cook-and-the-chef-musks-secret-sauce.html)
- [ ] [# How to Live with Chronic Imposter Syndrome](https://eugeneyan.com/writing/imposter-syndrome/); [Twitter source](https://twitter.com/eugeneyan/status/1381769166684708865?s=1001)
- [ ] [Modern Artificial Intelligence 1980s - 2021 by SchmidhuberAI!](https://twitter.com/radekosmulski/status/1381971368531517443?s=1001); [the talk](https://gtc21.event.nvidia.com/media/1_t3thb4sx)
- [ ] [Bayesian workflow](http://www.stat.columbia.edu/~gelman/research/unpublished/Bayesian_Workflow_article.pdf)
- [ ] [# A Recipe for Training Neural Networks](http://karpathy.github.io/2019/04/25/recipe/)
- [ ] [# Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531).
- [ ] [# Understanding the Disharmony between Dropout and Batch Normalization by Variance Shift](https://arxiv.org/abs/1801.05134)
- [ ] [Basic AI knowledge in simple terms](https://twitter.com/TivadarDanka/status/1383041991240519681?s=1001)
- [ ] atomic habits by james clear => deep work by cal newport =>can't hurt me by david goggins
- [x] [# Soft-launching an AI/ML Product as a Solo Founder](https://towardsdatascience.com/soft-launching-an-ai-ml-product-as-a-solo-founder-87ee81bbe6f6)
- [ ] [Yes you should understand backprop](https://karpathy.medium.com/yes-you-should-understand-backprop-e2f06eab496b)
- [ ] [Metagame of applying machine learning](https://eugeneyan.com/writing/machine-learning-metagame/);[Twitter](https://twitter.com/eugeneyan/status/1389732574289874949?s=1001)
- [ ] [MLflow: Platform for managing end-to-end machine learning lifecycle](https://www.mlflow.org/docs/latest/index.html)

- [ ] [Fast.ai cheat sheet](https://www.cognitivefactory.fr/fastaidocs/)
- [ ] [Testing your model using small subset of imageNet](https://github.com/fastai/imagenette)
- [ ] [# Continual Learning in Practice](https://arxiv.org/abs/1903.05202)
- [ ] [Full Stack Deep Learning course](https://fullstackdeeplearning.com/)
- [ ] [Book: Leadership Step by Step: Become the Person Others Follow]()
- [ ] [Paper: “Everyone wants to do the model work, not the data work]()
- [ ] [Talks about SOTA explainable ML](https://twitter.com/hima_lakkaraju/status/1390754121322467330?s=1001)
- [ ] [# PyTorch Ecosystem Day 2021](https://pytorch.org/ecosystem/pted/2021)
- [ ] [# Machine Learning Engineering for Production (MLOps) Specialization](https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops)
- [ ] [How other companies started a machine learning project](https://twitter.com/eugeneyan/status/1350509546133811200?s=1001)
- [ ] [AI Expert Roadmap](https://i.am.ai/roadmap)
- [ ] [**# Summary: My Paper Reading Lists, Tutorials & Sharings**](https://sh-tsang.medium.com/overview-my-reviewed-paper-lists-tutorials-946ce59fbf9e)



# AI model related
- [ ] [# Deep Learning for Computer Vision - Michigan Uni](https://www.youtube.com/playlist?list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r)
- [ ] [Understanding deep learning (still) require rethinking generalization](https://m-cacm.acm.org/magazines/2021/3/250713-understanding-deep-learning-still-requires-rethinking-generalization/fulltext)
- [ ] [How positional embeddings work in self-attention](https://theaisummer.com/positional-embeddings/?utm_content=155402435&utm_medium=social&utm_source=twitter&hss_channel=tw-1259466268505243649)
- [ ] [GradInit](https://arxiv.org/abs/2102.08098)
- [ ] - [ ] [Multimodal Neurons in Artificial Neural Networks](https://openai.com/blog/multimodal-neurons/)
- [ ] [Self-supervised learning: The dark matter of intelligence](https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence)
- [ ] [# Self-supervised Pretraining of Visual Features in the Wild](https://arxiv.org/abs/2103.01988)
- [ ] [# Do Transformer Modifications Transfer Across Implementations and Applications?](https://arxiv.org/abs/2102.11972)
- [ ] [# Ultra-Data-Efficient GAN Training: Drawing A Lottery Ticket First, Then Training It Toughly](https://arxiv.org/abs/2103.00397)
- [ ] [Pytorch state-of-the-art self-supervised learning](https://vissl.ai/)

- [ ] [Computer vision fundamental youtube series](https://www.youtube.com/channel/UCf0WB91t8Ky6AuYcQV0CcLw/featured?app=desktop)
- [ ] [# Efficient Transformers: A Survey](https://arxiv.org/abs/2009.06732)
- [ ] [# DeepViT: Towards Deeper Vision Transformer](https://arxiv.org/abs/2103.11886)
- [ ] [Explaining multi-headed self attention](https://theaisummer.com/self-attention/)
- [ ] [Pytorch profiler](https://pytorch.org/blog/introducing-pytorch-profiler-the-new-and-improved-performance-tool/)
- [ ] [# How to decay your learning rate](https://arxiv.org/abs/2103.12682)
- [ ] [# The Design and Implementation of **XiaoIce**, an Empathetic Social Chatbot](https://arxiv.org/abs/1812.08989)
- [ ] [# Language model fusion for streaming end to end speech recognition](https://arxiv.org/abs/2104.04487)
- [ ] [# RepVGG: Making VGG-style ConvNets Great Again](https://arxiv.org/abs/2101.03697); [Github](https://github.com/DingXiaoH/RepVGG)
- [ ] [# DatasetGAN: Efficient Labeled Data Factory with Minimal Human Effort](https://arxiv.org/abs/2104.06490)
- [ ] [OCR Layout Parser](https://arxiv.org/abs/2103.15348)
- [ ] [Speech recognition from scratch](https://colab.research.google.com/drive/1aFgzrUv3udM_gNJNUoLaHIm78QHtxdIz?usp=sharing)
- [ ] [NLP: # Sequence to Sequence (seq2seq) and Attention](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html)
- [ ] [# ResNet-RS models github](https://github.com/rwightman/pytorch-image-models/pull/554)
- [ ] [Aran Komatsuzaki's best 2020 papers: Scaling Laws for Neural Language Models;  An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale; (Improved) Denoising Diffusion Probabilistic Models](https://twitter.com/arankomatsuzaki/status/1388206521318842368?s=1001)
- [ ] [# MLP-Mixer: An all-MLP Architecture for Vision (smt better than transformer ❓)](https://arxiv.org/abs/2105.01601)
- [ ] [# Deep Learning for Recommender Systems (Nick Pentreath)](https://www.youtube.com/watch?app=desktop&v=y_TzOOCJqxI)
- [ ] [**# Rethinking "Batch" in BatchNorm**](https://arxiv.org/abs/2105.07576)
- [ ] [# 500 Deep Learning Questions](https://github.com/scutan90/DeepLearning-500-questions/tree/master/English%20version#sections-of-readme)











